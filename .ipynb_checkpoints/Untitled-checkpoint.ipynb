{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.envs.registration import registry, register, make, spec\n",
    "import Localizer_env\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal, MultivariateNormal\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import network and agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SAC_LSTM import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/home/mstaps/anaconda3/lib/python3.7/site-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mstaps/anaconda3/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'obs1': array([ 71.        ,  56.        , 112.60550608,   0.55059475,\n",
       "           0.83477268]),\n",
       "  'obs2': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]])},\n",
       " -1,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name = 'Local-v0'\n",
    "seed = 0\n",
    "n_episodes = 100\n",
    "GAMMA = 0.99\n",
    "TAU = 1e-2\n",
    "BUFFER_SIZE = int(1e6)\n",
    "BATCH_SIZE = 256\n",
    "LR_ACTOR = 5e-4\n",
    "LR_CRITIC = 5e-4\n",
    "# FIXED_ALPHA = \n",
    "# saved_model\n",
    "\n",
    "t0 = time.time()\n",
    "writer = SummaryWriter(\"runs/\")\n",
    "env = gym.make(env_name)\n",
    "\n",
    "env.reset()\n",
    "\n",
    "desired_action = np.array([0,0])\n",
    "env.step(desired_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space_2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs 2 shape: (200, 200)\n",
      "input_size_conv_out  582\n",
      "256\n",
      "128\n",
      "386\n",
      "128\n",
      "386\n",
      "128\n",
      "386\n",
      "128\n",
      "386\n",
      "128\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "Episode 1 Reward: -148.00  Average100 Score: -148.00next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "Episode 2 Reward: -5.00  Average100 Score: -76.50next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n",
      "next step shape (200, 200)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8fb99c73924f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m \u001b[0mSAC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-8fb99c73924f>\u001b[0m in \u001b[0;36mSAC\u001b[0;34m(n_episodes, max_t, print_every)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mstate_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Simple_localizer/SAC_LSTM.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state_1, state_2, action, reward, next_state_1, next_state_2, done, step)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Simple_localizer/SAC_LSTM.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;31m# Store state_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mstates_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "action_high = env.action_space.high[0]\n",
    "action_low = env.action_space.low[0]\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "np.random.seed(seed)\n",
    "state_size = dict()\n",
    "state_size['state_1'] = env.observation_space_1.shape[0]\n",
    "state_size['state_2'] = env.observation_space_2.shape[0]\n",
    "\n",
    "print(\"obs 2 shape:\",env.observation_space_2.shape)\n",
    "action_size = env.action_space.shape[0]\n",
    "\n",
    "NN_size = dict()\n",
    "NN_size = {'sequence_length': int(50),\n",
    "           'hidden_1_size': 128,\n",
    "           'hidden_1_num_layers': 4,\n",
    "           'input_channels': 1,\n",
    "           'hidden_channels': 1,\n",
    "           'output_channels': 1,\n",
    "           'kernel_size': 3,\n",
    "           'stride': 2,\n",
    "           'hidden_2_size': 256,\n",
    "           'hidden_2_out': 64,\n",
    "           'hidden_2_num_layers': 4,\n",
    "           'input_dims_last': 256,\n",
    "           'input_dims_last critic': 386,\n",
    "           'hidden_3_size': 128,\n",
    "           'hidden_3_out': 128,\n",
    "           'hidden_3_num_layers': 3,\n",
    "}\n",
    "\n",
    "\n",
    "agent = Agent(state_size=state_size, action_size=action_size, random_seed=seed, NN_size=NN_size, action_prior=\"uniform\") \n",
    "\n",
    "Batch_1_size = 1\n",
    "\n",
    "def SAC(n_episodes=200, max_t=500, print_every=10):\n",
    "    #\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    average_100_scores = []\n",
    "\n",
    "    state_1 = np.zeros((Batch_1_size, NN_size['sequence_length'], state_size['state_1']))\n",
    "    state_2 = np.zeros((Batch_1_size, NN_size['sequence_length'], state_size['state_2'], state_size['state_2'])) \n",
    "    \n",
    "    action_buffer = np.zeros((Batch_1_size, NN_size['sequence_length'], 2))\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        #\n",
    "        state = env.reset()\n",
    "        \n",
    "        state_1 = np.zeros((Batch_1_size, NN_size['sequence_length'], state_size['state_1']))\n",
    "        state_2 = np.zeros((Batch_1_size, NN_size['sequence_length'], state_size['state_2'], state_size['state_2'])) \n",
    "        \n",
    "        action_buffer = np.zeros((Batch_1_size, NN_size['sequence_length'], 2))\n",
    "        \n",
    "#         print(f' state obs1', state['obs1'])\n",
    "#         print(f' state obs2', state['obs2'])\n",
    "        # add next state to the sequence\n",
    "        state_1[0,-1] = state['obs1']\n",
    "        state_2[0,-1] = state['obs2']\n",
    "        \n",
    "        print('shape state_2: ', state_2[0,-1].shape)\n",
    "        next_state_1 = state_1\n",
    "        next_state_2 = state_2\n",
    "        \n",
    "        \n",
    "        score = 0\n",
    "        \n",
    "        for t in range(max_t):\n",
    "            \n",
    "            \n",
    "            state_1 = np.roll(state_1, -1, axis = 1)\n",
    "            state_2 = np.roll(state_2, -1, axis = 1)\n",
    "            \n",
    "            state_1[0,-1] = state['obs1']\n",
    "            state_2[0,-1] = state['obs2']\n",
    "                       \n",
    "            #\n",
    "            action = agent.act(state_1, state_2)\n",
    "            action_v = action.numpy()\n",
    "            action_v = action_v.reshape(2)\n",
    "            action_v = np.clip(action_v*action_high, action_low, action_high)\n",
    "            \n",
    "            next_state, reward, done, info = env.step(action_v)\n",
    "            \n",
    "\n",
    "            x_obs = next_state['obs1']\n",
    "            \n",
    "            print('next step shape',next_state['obs2'].shape)\n",
    "            next_state_1[0,-1] = next_state['obs1']\n",
    "            next_state_2[0,-1] = next_state['obs2']\n",
    "\n",
    "            \n",
    "            agent.step(state_1, state_2, action_v, reward, next_state_1, next_state_2, done, t)\n",
    "            \n",
    "            state_1, state_2 = next_state_1, next_state_2\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "            score += reward\n",
    "#             if( t%10 ==0):\n",
    "#                 print(f'episode number {i_episode} sim_time = {t}', end='\\r')\n",
    "            if done:\n",
    "                break \n",
    "        \n",
    "        scores_deque.append(score)\n",
    "        writer.add_scalar(\"Reward\", score, i_episode)\n",
    "        writer.add_scalar(\"average_X\", np.mean(scores_deque), i_episode)\n",
    "        average_100_scores.append(np.mean(scores_deque))\n",
    "        \n",
    "        print('\\rEpisode {} Reward: {:.2f}  Average100 Score: {:.2f}'.format(i_episode, score, np.mean(scores_deque)), end=\"\")\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}  Reward: {:.2f}  Average100 Score: {:.2f}'.format(i_episode, score, np.mean(scores_deque)))\n",
    "            \n",
    "    \n",
    "    torch.save(agent.actor_local.state_dict(), args.info + \".pt\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def play():\n",
    "    agent.actor_local.eval()\n",
    "    for i_episode in range(1):\n",
    "\n",
    "        state = env.reset()\n",
    "        \n",
    "        state_1 = state['obs1']\n",
    "        state_2 = state['obs2']\n",
    "        \n",
    "        state_1 = state_1.reshape((-1,state_size['state_1']))\n",
    "        state_2 = state_2.reshape((-1,state_size['state_2']))\n",
    "\n",
    "        while True:\n",
    "            #\n",
    "            action = agent.act(state_1, state_2)\n",
    "            \n",
    "            #\n",
    "            action_v = action[0].numpy()\n",
    "            \n",
    "            # \n",
    "            action_v = np.clip(action_v*action_high, action_low, action_high)\n",
    "            \n",
    "            next_state, reward, done, info = env.step(action_v)\n",
    "            \n",
    "            next_state_1 = next_state['obs1']\n",
    "            next_state_2 = next_state['obs2']\n",
    "            \n",
    "            next_state_1 = next_state_1.reshape((-1, state_size['state_1']))\n",
    "            next_state_2 = next_state_2.reshape((-1, state_size['state_2']))\n",
    "            \n",
    "            state_1 = next_state_1\n",
    "            state_2 = next_state_2\n",
    "            if done:\n",
    "                break \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "SAC(n_episodes = n_episodes, max_t=500, print_every=100)\n",
    "t1 = time.time()\n",
    "\n",
    "env.close()\n",
    "print(\"training took {} min!\".format((t1-t0)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros((200,200))\n",
    "x.reshape()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
